kpss.test(power_17)
power_17_diff <- diff(power_17,1)
kpss.test(power_17_diff) # Level stationary
kpss.test(temp_17)
temp_17_diff <- diff(temp_17,1)
kpss.test(temp_17_diff) # Level stationary
adf.test(power_17_diff)
adf.test(temp_17_diff)
# Both p-value < 0.05 --> Stationary
arima_fit <- auto.arima(power_17, xreg = temp_17, lambda = 0, trace = TRUE, d = 1, seasonal = TRUE, approximation = FALSE, stepwise = FALSE)
summary(arima_fit)
checkresiduals(arima_fit)
power
ts_temp
power_17
plot(power_17)
plot(temo_17)
plot(temp_17)
setwd("~/Desktop/Spring2021/Time/HW/Final")
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Convert Power Usage to Time Series - from 2017 to 2020
colnames(power) <- c('Date', 'Usage')
ts_power <- ts(power$Usage, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_power)
length(ts_power)
dim(power)
shapiro.test(as.vector(ts_power))
lambda <- BoxCox.lambda(ts_power)
lambda
ts_power %>% BoxCox(lambda =-0.9999242) %>% autoplot()
boxcox_power <- BoxCox(ts_power, lambda = -0.9999242)
decompose_power <- decompose(ts_power,"multiplicative")
autoplot(decompose_power) + theme_classic()
adjusted <- ts_power - decompose_power$seasonal
plot(adjusted)
fcses <- ses(adjusted)
autoplot(fcses)
checkresiduals(fcses)
fc.tbats <- forecast(tbats(ts_power, seasonal.periods=c(10.13514, 375)), h=60)
fcholt <- holt(adjusted)
autoplot(fcholt)
checkresiduals(fcholt)
fcholt2 <- holt(adjusted,damped = TRUE)
autoplot(fcholt2)
checkresiduals(fcholt2)
fcets <- ets(adjusted)
autoplot(fcets)
checkresiduals(fcets)
summary(fcets)
Model_Naive <- naive(adjusted)
autoplot(forecast(Model_Naive))
checkresiduals(Model_Naive)
summary(Model_Naive)
adf.test(boxcox_power)
boxcox_power %>% ur.kpss() %>% summary()
fit <- auto.arima(boxcox_power,max.p = 5,max.q = 5,max.P = 5,max.Q = 5,max.d = 3,seasonal = TRUE,ic = 'aicc')
plot(forecast(fit,h=20))
summary(fit)
checkresiduals(fit)
fit2 <- auto.arima(boxcox_power,max.p = 5,max.q = 5,max.P = 5,max.Q = 5,max.d = 3,seasonal = FALSE,ic = 'aicc')
plot(forecast(fit2,h=20))
str(fit2)
summary(fit2)
checkresiduals(fit2)
fit3 <- auto.arima(boxcox_power,max.p = 5,max.q = 5,max.P = 5,max.Q = 5,max.D = 0,seasonal = TRUE,ic = 'aicc')
plot(forecast(fit3,h=20))
fit3
eacf(boxcox_power)
m1.co2=Arima(boxcox_power,order=c(2,0,1),seasonal=list(order=c(0,0,1),period= 7,365))
m1.co2
p <- periodogram(boxcox_power)
data.table(period=1/p$freq, spec=p$spec)[order(-spec)][1:2]
require(data.table)
bestfit <- list(aicc=fit2$aicc, i=0, j=0, fit=fit2)
for(i in 1:3) {
for (j in 1:3){
z1 <- fourier(ts(boxcox_power, frequency=10.13514	), K=i)
z2 <- fourier(ts(boxcox_power, frequency=375.00000), K=j)
fit <- auto.arima(boxcox_power, xreg=cbind(z1, z2), seasonal=F)
if(fit$aicc < bestfit$aicc) {
bestfit <- list(aicc=fit$aicc, i=i, j=j, fit=fit)
}
}
}
bestfit
# Load weather data
weather <- read.csv('data/weather.csv')
head(weather)
# Extract the weather details
weather$Date <- substr(weather$Date, 1,10)
agg2 <- aggregate(weather[, c(4,7,10,13,16,18)], list(weather$Date), mean)
head(agg2)
# Use data from 2017 - 2019
weather <- agg2[substr(agg2$Group.1,1,4) == '2017' | substr(agg2$Group.1,1,4) =='2018'|substr(agg2$Group.1,1,4) =='2019',]
head(weather)
# Convert Average Temperature to Time Series - from 2017 to 2020
ts_temp <- ts(weather$Temp_avg, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_temp)
length(ts_temp)
dim(weather)
lm1 <- tslm(log(train)~log(temp_train))
lm1
fit2 <- auto.arima(boxcox_power,max.p = 5,max.q = 5,max.P = 5,max.Q = 5,max.d = 3,seasonal = FALSE,ic = 'aicc')
plot(forecast(fit2,h=20))
str(fit2)
summary(fit2)
fit <- auto.arima(boxcox_power,max.p = 5,max.q = 5,max.P = 5,max.Q = 5,max.d = 3,seasonal = TRUE,ic = 'aicc')
plot(forecast(fit,h=20))
str(fit)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
agg
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
ag
agg
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
power
# Conver to time sereis
colnames(power) <- c('Date', 'Usage')
# Time Series Plot
train <- ts(power$Usage, start = c(2017,1), end = c(2018,365),frequency = 365)
tsdisplay(train)
test <- ts(power$Usage, start = c(2018,1), end = c(2019,365),frequency = 365)
tsdisplay(test)
# Load weather data
weather <- read.csv('data/weather.csv')
head(weather)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
data
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
power
length(power)
length(power)
weather
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
agg
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
power
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
data
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
data
agg <- aggregate(data[, 2], list(data$StartDate), sum)
agg
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
power
View(power)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Conver to time sereis
colnames(power) <- c('Date', 'Usage')
# Time Series Plot
train <- ts(power$Usage, start = c(2017,1), end = c(2018,365),frequency = 365)
tsdisplay(train)
test <- ts(power$Usage, start = c(2018,1), end = c(2019,365),frequency = 365)
tsdisplay(test)
# Load weather data
weather <- read.csv('data/weather.csv')
head(weather)
# Extract the weather details
weather$Date <- substr(weather$Date, 1,10)
agg2 <- aggregate(weather[, c(4,7,10,13,16,18)], list(weather$Date), mean)
head(agg2)
# Use data from 2-17 - 2019
weather <- agg2[substr(agg2$Group.1,1,4) == '2017' | substr(agg2$Group.1,1,4) =='2018'|substr(agg2$Group.1,1,4) =='2019',]
head(weather)
# Convert Temperature to average
temp_train <- ts(weather$Temp_avg, start = c(2017,1), end = c(2018,365),frequency = 365)
tsdisplay(temp_train)
temp_test <- ts(weather$Temp_avg, start = c(2018,1), end = c(2019,365),frequency = 365)
tsdisplay(temp_test)
lm1 <- tslm(log(train)~log(temp_train))
lm1
# Check model fitting
plot(x = log(temp_train), y = log(train), col = 1)
abline(lm1, col = 2)
legend('topleft', legend = c('actual' , 'Trend'), col = 1:2, lty = 1)
# Evaluate results and residuals
summary(lm1)
checkresiduals(lm1)
setwd("~/Desktop/Spring2021/Time/HW/Final")
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
library(urca)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Convert Power Usage to Time Series - from 2017 to 2020
colnames(power) <- c('Date', 'Usage')
ts_power <- ts(power$Usage, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_power)
power_17 <- window(ts_power, start = c(2017,1), end = c(2017,365))
length(ts_power)
dim(power)
shapiro.test(as.vector(power_17))
lambda <- BoxCox.lambda(power_17)
lambda
fcses <- ses(power_17)
autoplot(fcses)
checkresiduals(fcses)
fcets <- ets(power_17)
autoplot(fcets)
checkresiduals(fcets)
summary(fcets)
Model_Naive <- naive(power_17)
autoplot(forecast(Model_Naive))
checkresiduals(Model_Naive)
summary(Model_Naive)
adf.test(power_17)
power_17 %>% ur.kpss() %>% summary()
fit <- auto.arima(power_17,seasonal = TRUE,ic = 'aicc')
plot(forecast(fit,h=20))
str(fit)
summary(fit)
checkresiduals(fit)
fit2 <- auto.arima(power_17,seasonal = FALSE,ic = 'aicc')
plot(forecast(fit2,h=20))
str(fit2)
summary(fit2)
checkresiduals(fit2)
eacf(power_17)
library('tidyverse')
library('tseries')
library('forecast')
fit3=Arima(power_17,order=c(7,1,8))
fit3
checkresiduals(fit3)
to_tibble <- function(forecast_object){
point_estimate <- forecast_object$mean %>%
as_tsibble() %>%
rename(point_estimate = value,
date = index)
upper <- forecast_object$upper %>%
as_tsibble() %>%
spread(key, value) %>%
rename(date = index,
upper80 = `80%`,
upper95 = `95%`)
lower <- forecast_object$lower %>%
as_tsibble() %>%
spread(key, value) %>%
rename(date = index,
lower80 = `80%`,
lower95 = `95%`)
reduce(list(point_estimate, upper, lower), full_join)
}
#Trend hyper parameters
order_list <- list("p" = seq(0, 10),
"d" = seq(0, 10),
"q" = seq(0, 10)) %>%
cross() %>%
map(lift(c))
#Seasonal hyper parameteres
season_list <- list("P" = seq(0, 10),
"D" = seq(0, 10),
"Q" = seq(0, 10),
"period" = 365)  %>%
cross() %>%
map(lift(c))
#Coerce vectors to tibbles
orderdf <- tibble("order" = order_list)
seasondf <- tibble("season" = season_list)
#Create grid of hyper-parameters
hyper_parameters_df <- crossing(orderdf, seasondf)
#Run grid search of ARIMA models
tic <- Sys.time()
models_df <- hyper_parameters_df %>%
mutate(models =
map2(.x = order,
.y = season,
~possibly(arima, otherwise = NULL)(x = power_17, order = .x, seasonal = .y)))
require(data.table)
lambda <- BoxCox.lambda(ts_power)
lambda
ts_power %>% BoxCox(lambda =-0.9999242) %>% autoplot()
boxcox_power <- BoxCox(ts_power, lambda = -0.9999242)
p <- periodogram(boxcox_power)
data.table(period=1/p$freq, spec=p$spec)[order(-spec)][1:2]
bestfit <- list(aicc=fit2$aicc, i=0, j=0, fit=fit2)
for(i in 1:3) {
for (j in 1:3){
z1 <- fourier(ts(boxcox_power, frequency=10.13514	), K=i)
z2 <- fourier(ts(boxcox_power, frequency=375.00000), K=j)
fit <- auto.arima(boxcox_power, xreg=cbind(z1, z2), seasonal=F)
if(fit$aicc < bestfit$aicc) {
bestfit <- list(aicc=fit$aicc, i=i, j=j, fit=fit)
}
}
}
bestfit
fc.tbats <- forecast(tbats(ts_power, seasonal.periods=c(10.13514, 375)), h=60)
# Load weather data
weather <- read.csv('data/weather.csv')
head(weather)
# Extract the weather details
weather$Date <- substr(weather$Date, 1,10)
agg2 <- aggregate(weather[, c(4,7,10,13,16,18)], list(weather$Date), mean)
head(agg2)
# Use data from 2017 - 2019
weather <- agg2[substr(agg2$Group.1,1,4) == '2017' | substr(agg2$Group.1,1,4) =='2018'|substr(agg2$Group.1,1,4) =='2019',]
head(weather)
# Convert Average Temperature to Time Series - from 2017 to 2020
ts_temp <- ts(weather$Temp_avg, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_temp)
length(ts_temp)
dim(weather)
lm1 <- tslm(log(train)~log(temp_train))
lm2 <- tslm(power_17_log ~ temp_17_log)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
library(urca)
# Load Power Data
data <- read.csv('power.csv')
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Convert Power Usage to Time Series - from 2017 to 2020
colnames(power) <- c('Date', 'Usage')
ts_power <- ts(power$Usage, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_power)
power_17 <- window(ts_power, start = c(2017,1), end = c(2017,365))
length(ts_power)
dim(power)
View(power)
View(data)
View(weather)
# Load weather data
weather <- read.csv('data/weather.csv')
head(weather)
View(weather)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Conver to time sereis
colnames(power) <- c('Date', 'Usage')
# Time Series Plot
train <- ts(power$Usage, start = c(2017,1),frequency = 365)
tsdisplay(train)
# Load Required Packages
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
library(urca)
# Load Power Data
data <- read.csv('data/power.csv')
head(data)
# Extract the daily power usage
data$StartDate <- substr(data$StartDate, 1,10)
agg <- aggregate(data[, 2], list(data$StartDate), sum)
head(agg)
# Use data from 2-17 - 2019
power <- agg[substr(agg$Group.1,1,4) == '2017' | substr(agg$Group.1,1,4) =='2018'|substr(agg$Group.1,1,4) =='2019',]
head(power)
# Convert Power Usage to Time Series - from 2017 to 2020
colnames(power) <- c('Date', 'Usage')
ts_power <- ts(power$Usage, start = c(2017,1), end = c(2019,365),frequency = 365)
tsdisplay(ts_power)
power_17 <- window(ts_power, start = c(2017,1), end = c(2017,365))
length(ts_power)
dim(power)
shapiro.test(as.vector(power_17))
lambda <- BoxCox.lambda(power_17)
lambda
fcses <- ses(power_17)
autoplot(fcses)
checkresiduals(fcses)
fcets <- ets(power_17)
autoplot(fcets)
checkresiduals(fcets)
summary(fcets)
Model_Naive <- naive(power_17)
autoplot(forecast(Model_Naive))
checkresiduals(Model_Naive)
summary(Model_Naive)
adf.test(power_17)
power_17 %>% ur.kpss() %>% summary()
fcses <- ses(power_17)
autoplot(fcses)
checkresiduals(fcses)
