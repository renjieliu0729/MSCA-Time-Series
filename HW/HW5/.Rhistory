fore1 <- forecast(auto,h=4,level = c(80, 95))
actual <- usgdp[usgdp$Year>2012,]
err <- actual$gdp - fore1$mean
actual$GDP
fore1 <- forecast(auto,h=4,level = c(80, 95))
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1$mean
fore1 <- forecast(auto,h=4,level = c(80, 95))
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1$mean
fore1$mean
err <- actual$GDP - fore1$mean[1]
plot(err)
sum((err)^2)
View(usgdp)
fore1$mean
# Forecase for four years so h = 4
plot(forecast(auto,h=4,level = c(80, 95)))
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- boxcox.inv(fore1 , lambda = 0.23)
library(fpp)
library(TSA)
load('usgdp.rda')
gdp <- ts(usgdp$GDP, frequency = 1,start = 1960)
train <- window(gdp,start = 1960, end = 2012)
test <- window(gdp,start = 2013, end = 2017)
plot(train)
# The box - cox transformation is necessary for this data because the data is increasing exponentianally. larger variance between lags as time progress.
BoxCox.lambda(train)
train <- BoxCox(train, lambda = 0.23)
plot(train)
library(tseries)
# first order difference of the data
plot(diff(train,differences = 1))
# second order difference of the data
plot(diff(train,differences = 2))
#Use kpss.test to test stationary
kpss.test(diff(train,differences = 1))
kpss.test(diff(train,differences = 2))
# Based on the kpss test. Both the first and second order difference of the data is stationary. Because the p-value is larger than 0.05, so fail to reject the null hypothesis that the time series is stationary.
auto <- auto.arima(train,seasonal = FALSE)
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
eacf(train)
# based on the eacf, p and q can have the combination of (1,1),(1,2),(2,1)
summary(Arima(train, order=c(1,1,1), include.drift = TRUE))
summary(Arima(train, order=c(1,1,2),include.drift = TRUE))
summary(Arima(train, order=c(2,1,1),include.drift = TRUE))
# Based on the AICc value. the auto arima model has the smallest AICc value. It is better than the than the three Arima models. Becuase the AICc = 444.88 which is the lowest.
# Forecase for four years so h = 4
plot(forecast(auto,h=4,level = c(80, 95)))
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- boxcox.inv(fore1 , lambda = 0.23)
auto <- auto.arima(train,seasonal = FALSE)
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
auto <- auto.arima(train,seasonal = FALSE)
auto
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- rbox(fore1 , lambda = 0.23)
fore1 <- forecast(auto,h=4,level = c(80, 95))
invBoxCox <- function(x, lambda)
if (lambda == 0) exp(x) else (lambda*x + 1)^(1/lambda)
fore1 <- invBoxCox (fore1 , 0.23)
fore1 <- forecast(auto,h=4,level = c(80, 95))
invBoxCox <- function(x, lambda)
if (lambda == 0) exp(x) else (lambda*x + 1)^(1/lambda)
fore1 <- invBoxCox (fore1$mean[1] , 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
fore1 <- forecast(auto,h=4,level = c(80, 95))
invBoxCox <- function(x, lambda)
if (lambda == 0) exp(x) else (lambda*x + 1)^(1/lambda)
fore1 <- invBoxCox (fore1$mean[1] , 0.23)
core1
fore1
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1
fore1 <- invBoxCox(fore1$mean[1] , 0.23)
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1 <- invBoxCox(fore1 , 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
library(fpp)
library(TSA)
load('usgdp.rda')
gdp <- ts(usgdp$GDP, frequency = 1,start = 1960)
train <- window(gdp,start = 1960, end = 2012)
test <- window(gdp,start = 2013, end = 2017)
plot(train)
# The box - cox transformation is necessary for this data because the data is increasing exponentianally. larger variance between lags as time progress.
BoxCox.lambda(train)
train <- BoxCox(train, lambda = 0.23)
plot(train)
library(tseries)
# first order difference of the data
plot(diff(train,differences = 1))
# second order difference of the data
plot(diff(train,differences = 2))
#Use kpss.test to test stationary
kpss.test(diff(train,differences = 1))
kpss.test(diff(train,differences = 2))
# Based on the kpss test. Both the first and second order difference of the data is stationary. Because the p-value is larger than 0.05, so fail to reject the null hypothesis that the time series is stationary.
auto <- auto.arima(train,seasonal = FALSE)
auto
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
eacf(train)
# based on the eacf, p and q can have the combination of (1,1),(1,2),(2,1)
summary(Arima(train, order=c(1,1,1), include.drift = TRUE))
summary(Arima(train, order=c(1,1,2),include.drift = TRUE))
summary(Arima(train, order=c(2,1,1),include.drift = TRUE))
# Based on the AICc value. the auto arima model has the smallest AICc value. It is better than the than the three Arima models. Becuase the AICc = 444.88 which is the lowest.
# Forecase for four years so h = 4
plot(forecast(auto,h=4,level = c(80, 95)))
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1 <- invBoxCox(fore1 , 0.23)
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1 <- InvBoxCox(fore1 , 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
library(fpp)
library(TSA)
load('usgdp.rda')
gdp <- ts(usgdp$GDP, frequency = 1,start = 1960)
train <- window(gdp,start = 1960, end = 2012)
test <- window(gdp,start = 2013, end = 2017)
plot(train)
# The box - cox transformation is necessary for this data because the data is increasing exponentianally. larger variance between lags as time progress.
BoxCox.lambda(train)
train <- BoxCox(train, lambda = 0.23)
plot(train)
library(tseries)
# first order difference of the data
plot(diff(train,differences = 1))
# second order difference of the data
plot(diff(train,differences = 2))
#Use kpss.test to test stationary
kpss.test(diff(train,differences = 1))
kpss.test(diff(train,differences = 2))
# Based on the kpss test. Both the first and second order difference of the data is stationary. Because the p-value is larger than 0.05, so fail to reject the null hypothesis that the time series is stationary.
auto <- auto.arima(train,seasonal = FALSE)
auto
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
eacf(train)
# based on the eacf, p and q can have the combination of (1,1),(1,2),(2,1)
summary(Arima(train, order=c(1,1,1), include.drift = TRUE))
summary(Arima(train, order=c(1,1,2),include.drift = TRUE))
summary(Arima(train, order=c(2,1,1),include.drift = TRUE))
# Based on the AICc value. the auto arima model has the smallest AICc value. It is better than the than the three Arima models. Becuase the AICc = 444.88 which is the lowest.
# Forecase for four years so h = 4
plot(forecast(auto,h=4,level = c(80, 95)))
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1 <- InvBoxCox(fore1 , 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
sum((err)^2)
fore1
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1]
fore1
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1
fore1$mean
fore1$mean[1]
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean
fore1 <- InvBoxCox(fore1 , 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
fore1
fore1[1]
fore1[1:4]
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1:4]
fore1 <- InvBoxCox(fore1, 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
sum((err)^2)
fore1
actual
actual$GDP
fore1
actual$GDP-fore1
library(fpp)
library(TSA)
load('usgdp.rda')
gdp <- ts(usgdp$GDP, frequency = 1,start = 1960)
train <- window(gdp,start = 1960, end = 2012)
test <- window(gdp,start = 2013, end = 2017)
plot(train)
# The box - cox transformation is necessary for this data because the data is increasing exponentianally. larger variance between lags as time progress.
BoxCox.lambda(train)
train <- BoxCox(train, lambda = 0.23)
plot(train)
library(tseries)
# first order difference of the data
plot(diff(train,differences = 1))
# second order difference of the data
plot(diff(train,differences = 2))
#Use kpss.test to test stationary
kpss.test(diff(train,differences = 1))
kpss.test(diff(train,differences = 2))
# Based on the kpss test. Both the first and second order difference of the data is stationary. Because the p-value is larger than 0.05, so fail to reject the null hypothesis that the time series is stationary.
auto <- auto.arima(train,seasonal = FALSE)
auto
## The best model from auto arima is p = 1, d = 1, and q = 0. This means that the model uses first order auto regression with first order differencing, and the model does not have moving average in the model. Drift is the intercept of the model. The Coefficients for ar1 is 0.4731
eacf(train)
# based on the eacf, p and q can have the combination of (1,1),(1,2),(2,1)
summary(Arima(train, order=c(1,1,1), include.drift = TRUE))
summary(Arima(train, order=c(1,1,2),include.drift = TRUE))
summary(Arima(train, order=c(2,1,1),include.drift = TRUE))
# Based on the AICc value. the auto arima model has the smallest AICc value. It is better than the than the three Arima models. Becuase the AICc = 444.88 which is the lowest.
# Forecase for four years so h = 4
plot(forecast(auto,h=4,level = c(80, 95)))
fore1 <- forecast(auto,h=4,level = c(80, 95))
fore1 <- fore1$mean[1:4]
fore1 <- InvBoxCox(fore1, 0.23)
actual <- usgdp[usgdp$Year>2012,]
err <- actual$GDP - fore1
plot(err)
# The forecase is getting larger.
sum((err)^2)
library(TSA)
library(fpp)
library(forecast)
library(TSA)
library(fpp)
library(forecast)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
tsdisplay(diff(train,lag = 1))
kpss.test(diff(train,lag = 1))
tsdisplay(diff(train,lag = 1))
kpss.test(diff(train,lag = 1))
auto <- auto.arima(train, stepwise = FALSE, approximation =FALSE)
auto
a1 <- Arima(train, order = c(1,1,0), seasonal = c(2,1,0))
a1
a1 <- auto.arima(train, stepwise = FALSE, approximation =FALSE, d = 1,D = 1)
a1 <- auto.arima(train, stepwise = FALSE, approximation =FALSE, d = 1,D = 1)
a1
a1 <- Arima(train, order = c(1,1,0), seasonal = c(2,1,0))
a1
tsdisplay(train)
adf.test(train)
adf.test(train)
adf.test(diff(train,1))
adf.test(train)
adf.test(diff(train,2))
adf.test(train)
adf.test(diff(train,12))
adf.test(train)
adf.test(diff(train,8))
adf.test(train)
adf.test(diff(train,9))
adf.test(train)
adf.test(diff(train,10))
adf.test(train)
adf.test(diff(train,11))
adf.test(train)
adf.test(diff(train,12))
adf.test(train)
adf.test(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,differences = 2))
adf.test(train)
adf.test(diff(train,differences = 10))
adf.test(train)
adf.test(diff(train,differences = 12))
adf.test(train)
adf.test(diff(train,differences = 100))
adf.test(train)
adf.test(diff(train,lag = 12))
auto <- auto.arima(train, stepwise = FALSE, approximation =FALSE)
auto
a1 <- Arima(train, order = c(1,1,0), seasonal = c(2,1,0))
a1
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
library(TSA)
library(fpp)
library(forecast)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
auto <- auto.arima(train, stepwise = FALSE, approximation =FALSE)
auto
a1 <- Arima(train, order = c(1,1,0), seasonal = c(2,1,0))
a1
checkresiduals(auto)
checkresiduals(auto$residuals)
checkresiduals(a1)
checkresiduals(auto)
checkresiduals(a1)
checkresiduals(auto)
checkresiduals(a1)
forecast(auto, h=12)
autof <-forecast(auto, h=12)
a1f <- forecast(a1, h =12)
autof <-forecast(auto, h=12)
a1f <- forecast(a1, h =12)
autoplot(condmilk) +
autolayer(autof$mean, series="Auto ARIMA") +
autolayer(a1f$mean, series="ARIMA1") +
ggtitle("Forecasts") +
xlab("Date")
library(TSA)
library(fpp)
library(forecast)
library(ggplot)
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
autof <-forecast(auto, h=12)
a1f <- forecast(a1, h =12)
autoplot(condmilk) +
autolayer(autof$mean, series="Auto ARIMA") +
autolayer(a1f$mean, series="ARIMA1") +
ggtitle("Forecasts") +
xlab("Date")
autof <-forecast(auto, h=12)
a1f <- forecast(a1, h =12)
autoplot(test) +
autolayer(autof$mean, series="Auto ARIMA") +
autolayer(a1f$mean, series="ARIMA1") +
ggtitle("Forecasts") +
xlab("Date")
accuracy(autof,test)
accuracy(a1,test)
accuracy(autof,test)
accuracy(af1,test)
accuracy(autof,test)
accuracy(a1f,test)
setwd("~/Desktop/Spring2021/Time/HW/HW5")
snf <- snaive(train, h = 12)
autoplot(test) +
autolayer(snf$mean, series="Seasonal Naive") +
ggtitle("Forecasts") +
xlab("Date")
accuracy(snf,test)
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
shapiro.test(train)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
shapiro.test(train)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
shapiro.test(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
adf.test(train,lag = 12)
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
shapiro.test(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
adf.test(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
shapiro.test(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
adf.test(train)
adf.test(diff(train,lag = 12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
library(TSA)
library(fpp)
library(forecast)
library(ggplot2)
load('condmilk.rda')
plot(condmilk)
train <- window(condmilk,start = c(1971,1) ,end = c(1979,12))
test <- window(condmilk, start = c(1980,1), end = c(1980,12))
tsdisplay(train)
adf.test(train)
adf.test(diff(train,lag = 12))
tsdisplay(diff(train,lag = 12))
auto <- auto.arima(train, stepwise = FALSE, approximation =FALSE, seasonal = TRUE)
auto
a1 <- auto.arima(train, stepwise = FALSE, approximation =FALSE, d = 1, D =1, seasonal = TRUE)
a1
auto <- auto.arima(train, stepwise = FALSE, approximation =FALSE, seasonal = TRUE)
auto
a1 <- auto.arima(train, stepwise = FALSE, approximation =FALSE, d = 1, D =1, seasonal = TRUE)
a1
checkresiduals(auto)
checkresiduals(a1)
autof <-forecast(auto, h=12)
a1f <- forecast(a1, h =12)
autoplot(test) +
autolayer(autof$mean, series="Auto ARIMA") +
autolayer(a1f$mean, series="ARIMA1") +
ggtitle("Forecasts") +
xlab("Date")
accuracy(autof,test)
accuracy(a1f,test)
snf <- snaive(train, h = 12)
autoplot(test) +
autolayer(snf$mean, series="Seasonal Naive") +
ggtitle("Forecasts") +
xlab("Date")
accuracy(snf,test)
Box.test (auto$residuals, lag = 12, type = "Ljung")
Box.test (a1$residuals, lag = 12, type = "Ljung")
